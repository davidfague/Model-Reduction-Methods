{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkDUft5LZQwYn0e76Gp4+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Model-Reduction-Methods/blob/main/Expansion_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMAnFoIqCb18",
        "outputId": "54b18115-5fa5-4897-d661-77858a488c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron\n",
            "  Downloading NEURON-8.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.9/dist-packages (from neuron) (1.22.4)\n",
            "Installing collected packages: neuron\n",
            "Successfully installed neuron-8.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron_reduce\n",
            "  Downloading neuron_reduce-0.0.7-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: neuron_reduce\n",
            "Successfully installed neuron_reduce-0.0.7\n",
            "Cloning into 'Model-Reduction-Methods'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 245 (delta 100), reused 176 (delta 61), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (245/245), 1.18 MiB | 3.49 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install neuron\n",
        "!pip install neuron_reduce\n",
        "!git clone https://github.com/davidfague/Model-Reduction-Methods.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Model-Reduction-Methods/\n",
        "\n",
        "#import reduction and expansion functions\n",
        "from test_neuron_reduce.subtree_reductor_func import subtree_reductor\n",
        "from cable_expander_func import cable_expander\n",
        "\n",
        "#import analysis functions\n",
        "from utils import make_seg_df,generate_stylized_geometry,make_reduced_seg_df,plot_morphology\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXyQKeweDBt5",
        "outputId": "fd7408bd-0f9f-484d-9096-feacc230f9c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Model-Reduction-Methods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd expand_example\n",
        "# compile the mod files\n",
        "!nrnivmodl mod"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWg3wWDeDALy",
        "outputId": "fd19ddcb-4cac-45f0-d568-48ecbc1d0af0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Model-Reduction-Methods/expand_example\n",
            "/content/Model-Reduction-Methods/expand_example\n",
            "Mod files: \"mod/mod/CaDynamics_E2.mod\" \"mod/mod/Ca_HVA.mod\" \"mod/mod/Ca_LVAst.mod\" \"mod/mod/epsp.mod\" \"mod/mod/Ih.mod\" \"mod/mod/Im.mod\" \"mod/mod/K_Pst.mod\" \"mod/mod/K_Tst.mod\" \"mod/mod/Nap_Et2.mod\" \"mod/mod/NaTa_t.mod\" \"mod/mod/NaTs2_t.mod\" \"mod/mod/SK_E2.mod\" \"mod/mod/SKv3_1.mod\"\n",
            "\n",
            "Creating 'x86_64' directory for .o files.\n",
            "\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/CaDynamics_E2.mod\n",
            " -> \u001b[32mCompiling\u001b[0m mod_func.cpp\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ca_HVA.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ca_LVAst.mod\n",
            "Translating CaDynamics_E2.mod into /content/Model-Reduction-Methods/expand_example/x86_64/CaDynamics_E2.c\n",
            "Thread Safe\n",
            "Translating Ca_HVA.mod into /content/Model-Reduction-Methods/expand_example/x86_64/Ca_HVA.c\n",
            "Translating Ca_LVAst.mod into /content/Model-Reduction-Methods/expand_example/x86_64/Ca_LVAst.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ih.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/epsp.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Im.mod\n",
            "Translating Ih.mod into /content/Model-Reduction-Methods/expand_example/x86_64/Ih.c\n",
            "Translating epsp.mod into /content/Model-Reduction-Methods/expand_example/x86_64/epsp.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            "Translating Im.mod into /content/Model-Reduction-Methods/expand_example/x86_64/Im.c\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/K_Pst.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/K_Tst.mod\n",
            "Translating K_Pst.mod into /content/Model-Reduction-Methods/expand_example/x86_64/K_Pst.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Nap_Et2.mod\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/NaTa_t.mod\n",
            "Translating Nap_Et2.mod into /content/Model-Reduction-Methods/expand_example/x86_64/Nap_Et2.c\n",
            "Translating K_Tst.mod into /content/Model-Reduction-Methods/expand_example/x86_64/K_Tst.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/NaTs2_t.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/SK_E2.mod\n",
            "Translating NaTa_t.mod into /content/Model-Reduction-Methods/expand_example/x86_64/NaTa_t.c\n",
            "Thread Safe\n",
            "Translating SK_E2.mod into /content/Model-Reduction-Methods/expand_example/x86_64/SK_E2.c\n",
            "Translating NaTs2_t.mod into /content/Model-Reduction-Methods/expand_example/x86_64/NaTs2_t.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/SKv3_1.mod\n",
            " -> \u001b[32mCompiling\u001b[0m CaDynamics_E2.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_HVA.c\n",
            "Translating SKv3_1.mod into /content/Model-Reduction-Methods/expand_example/x86_64/SKv3_1.c\n",
            "Thread Safe\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_LVAst.c\n",
            " -> \u001b[32mCompiling\u001b[0m epsp.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ih.c\n",
            " -> \u001b[32mCompiling\u001b[0m Im.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Pst.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Tst.c\n",
            " -> \u001b[32mCompiling\u001b[0m Nap_Et2.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTa_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTs2_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m SK_E2.c\n",
            " -> \u001b[32mCompiling\u001b[0m SKv3_1.c\n",
            " => \u001b[32mLINKING\u001b[0m shared library ./libnrnmech.so\n",
            " => \u001b[32mLINKING\u001b[0m executable ./special LDFLAGS are:    -pthread\n",
            "Successfully created x86_64/special\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check mechanisms"
      ],
      "metadata": {
        "id": "V-L-5q8YOFUy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "bKyG2QqoiLqt",
        "outputId": "114bf5df-ce28-4dbe-89a6-857ee38c8664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell1.asc  example_expand.py  L5PCtemplate.hoc  \u001b[0m\u001b[01;34mx86_64\u001b[0m/\n",
            "Cell.hoc   L5PCbiophys3.hoc   \u001b[01;34mmod\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define The Cell"
      ],
      "metadata": {
        "id": "6XTLUFd_DxNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the code\n",
        "from __future__ import division\n",
        "from neuron import gui,h\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Create a L5_PC model\n",
        "h.load_file('L5PCbiophys3.hoc')\n",
        "h.load_file(\"import3d.hoc\")\n",
        "h.load_file('L5PCtemplate.hoc')\n",
        "complex_cell = h.L5PCtemplate('cell1.asc')\n",
        "h.celsius = 37\n",
        "h.v_init = complex_cell.soma[0].e_pas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJeAEkZADp4X",
        "outputId": "49b71c8c-6b50-487a-d274-8756307c72be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "NEURON: Ca_LVAst is not a MECHANISM\n",
            " in L5PCbiophys3.hoc near line 21\n",
            " \t  insert Ca_LVAst \n",
            "                  ^\n",
            "        xopen(\"L5PCbiophy...\")\n",
            "      execute1(\"{xopen(\"L5...\")\n",
            "    load_file(\"L5PCbiophy...\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add synapses to the cell"
      ],
      "metadata": {
        "id": "mqHtu0wiDurL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Add synapses to the model\n",
        "synapses_list, netstims_list, netcons_list, randoms_list = [], [], [] ,[]\n",
        "\n",
        "all_segments = [i for j in map(list,list(complex_cell.apical)) for i in j] + [i for j in map(list,list(complex_cell.basal)) for i in j]\n",
        "len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in all_segments])\n",
        "rnd = np.random.RandomState(10)\n",
        "for i in range(10000):\n",
        "    seg_for_synapse = rnd.choice(all_segments,   p=len_per_segment/sum(len_per_segment)) #choose a random segment with probability based on the length of segment\n",
        "    synapses_list.append(h.Exp2Syn(seg_for_synapse))\n",
        "    if rnd.uniform()<0.85: # 85% synapses are excitatory\n",
        "        e_syn, tau1, tau2, spike_interval, syn_weight = 0, 0.3, 1.8,  1000/2.5, 0.0016\n",
        "    else: #inhibitory case\n",
        "        e_syn, tau1, tau2, spike_interval, syn_weight = -86, 1,   8,   1000/15.0, 0.0008\n",
        "    #set synaptic varibales\n",
        "    synapses_list[i].e, synapses_list[i].tau1, synapses_list[i].tau2 = e_syn, tau1, tau2\n",
        "    #set netstim variables\n",
        "    netstims_list.append(h.NetStim())\n",
        "    netstims_list[i].interval, netstims_list[i].number, netstims_list[i].start, netstims_list[i].noise = spike_interval, 9e9, 100, 1\n",
        "    #set random\n",
        "    randoms_list.append(h.Random())\n",
        "    randoms_list[i].Random123(i)\n",
        "    randoms_list[i].negexp(1)\n",
        "    netstims_list[i].noiseFromRandom(randoms_list[i])       \n",
        "    #set netcon varibales \n",
        "    netcons_list.append(h.NetCon(netstims_list[i], synapses_list[i] ))\n",
        "    netcons_list[i].delay, netcons_list[i].weight[0] = 0, syn_weight"
      ],
      "metadata": {
        "id": "ZTB0osm3Ds4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulate the complex cell"
      ],
      "metadata": {
        "id": "hNTxiiZMD228"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soma_v = h.Vector()\n",
        "soma_v.record(complex_cell.soma[0](0.5)._ref_v)\n",
        "\n",
        "time_v = h.Vector()\n",
        "time_v.record(h._ref_t)\n",
        "\n",
        "h.tstop = 1000\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('complex cell simulation time {:.4f}'.format(time.time()-st))\n",
        "complex_cell_v = list(soma_v)"
      ],
      "metadata": {
        "id": "e8arDkunD3Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Neuron_Reduce to turn each dendritic tree into a semi-equivalent cable"
      ],
      "metadata": {
        "id": "dXAJkOOTD8nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply Neuron_Reduce to simplify the cell\n",
        "reduced_cell, synapses_list, netcons_list, txt = subtree_reductor(complex_cell, synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)\n",
        "for r in randoms_list:r.seq(1) #reset random\n",
        "\n",
        "\n",
        "#Running the simulation again but now on the reduced cell\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('reduced cell simulation time {:.4f}'.format(time.time()-st))\n",
        "reduced_celll_v = list(soma_v)\n",
        "\n",
        "#plotting the results\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(time_v, complex_cell_v, label='complex cell')\n",
        "plt.plot(time_v, reduced_celll_v,  label='reduced cell')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xrI_CMmvD6yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use cable_expander to turn each cable into an equivalent idealized dendritic tree"
      ],
      "metadata": {
        "id": "1Y07JYqZEKoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#indicate the complex branching segment # may have to observe complex cell first\n",
        "complex_branching_segment='L5PCtemplate[0].apic[36](0.961538)'\n",
        "#get the reduced segment that the complex nexus branching segment mapped to\n",
        "branching_seg=txt.get(complex_branching_segment)\n",
        "branching_seg = branching_seg.replace(\"[0]\", \"\",1)\n",
        "branching_seg=\"reduced_cell.hoc_\"+branching_seg\n",
        "print('branching_seg: ',branching_seg)\n",
        "\n",
        "# get section_to_expand and the furcation x loc\n",
        "branching_seg_data=branching_seg.split('(')\n",
        "section_to_expand=branching_seg_data[0]\n",
        "furcation_x=branching_seg_data[1].strip(')')\n",
        "#indicate lists for cable_expander()\n",
        "sections_to_expand=[section_to_expand]\n",
        "furcations_x=[furcation_x]\n",
        "nbranches=[4] #choose nbranches #possible implementation could automatically count the number of times the seg immediately branches, but would not necessary account for later branching"
      ],
      "metadata": {
        "id": "vlHi0EPEEVZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_dendritic_cell, synapses_list, netcons_list, txt = cable_expander(reduced_cell, sections_to_expand, furcations_x, nbranches, \n",
        "                                                                          synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)"
      ],
      "metadata": {
        "id": "yXvIBv7XHjDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the simulation again but now on the reduced cell\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('reduced cell simulation time {:.4f}'.format(time.time()-st))\n",
        "expanded_cellll_v = list(soma_v)\n",
        "\n",
        "#plotting the results\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(time_v, complex_cell_v, label='complex cell')\n",
        "plt.plot(time_v, reduced_celll_v,  label='reduced cell')\n",
        "plt.plot(time_v, expanded_cellll_v,  label='reduced dendritic cell')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "soEkAF4LMXeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Cells"
      ],
      "metadata": {
        "id": "5ucTxST3LQqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_seg_df(complex_cell,\"segments_complex.csv\")"
      ],
      "metadata": {
        "id": "7gRAY74mLVZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complex_segments_df=pd.read_csv(\"segments_complex.csv\")"
      ],
      "metadata": {
        "id": "gLhoekrzLSxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_stylized_geometry(cell=complex_cell,savename='geom_complex.csv')"
      ],
      "metadata": {
        "id": "ssktUpfuLYpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_reduced_seg_df(reduced_cell,\"segments_reduced.csv\")"
      ],
      "metadata": {
        "id": "Zoc3PmdTLat6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_reduced_seg_df(reduced_dendritic_cell,\"segments_expanded.csv\")"
      ],
      "metadata": {
        "id": "GgZdZOLBOhjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_segments_df=pd.read_csv(\"segments_reduced.csv\")"
      ],
      "metadata": {
        "id": "NcqcmftjLbsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_segments_df=pd.read_csv(\"segments_expanded.csv\")"
      ],
      "metadata": {
        "id": "wiWhqW10ORCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology(complex_segments_df,'complex_morphology.svg')"
      ],
      "metadata": {
        "id": "JrqAvcUHLgLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology(reduced_segments_df,\"reduced_morphology.svg\")"
      ],
      "metadata": {
        "id": "3w6LmUsHLiCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology(expanded_segments_df,\"expanded_morphology.svg\")"
      ],
      "metadata": {
        "id": "AZn1qS15OLTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}